{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e3a34b2-78e7-475c-958f-cd6db4713d2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#==========================\n",
    "# Real-Time Retail Pipeline\n",
    "# Event Hub → Bronze → Silver → Gold\n",
    "# ==========================\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, DoubleType\n",
    "from pyspark.sql.functions import col, from_json, sum as _sum, avg as _avg, countDistinct\n",
    "import json\n",
    "with open(\"/dbfs/FileStore/configs/config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "# ==========================\n",
    "# 1. Spark Session\n",
    "# ==========================\n",
    "spark = SparkSession.builder.appName(\"RealTimeRetailPipeline\").getOrCreate()\n",
    "\n",
    "# ==========================\n",
    "# 2. Event Hub Configuration\n",
    "# ==========================\n",
    "eh_connection_string = config[\"eventhub\"][\"connection_string\"]\n",
    "\n",
    "# Encrypt for Spark connector\n",
    "ehConf = {\n",
    "    'eventhubs.connectionString': sc._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(eh_connection_string)\n",
    "}\n",
    "\n",
    "# ==========================\n",
    "# 3. Define Schema\n",
    "# ==========================\n",
    "schema = StructType() \\\n",
    "    .add(\"InvoiceNo\", StringType()) \\\n",
    "    .add(\"StockCode\", StringType()) \\\n",
    "    .add(\"Description\", StringType()) \\\n",
    "    .add(\"Quantity\", StringType()) \\\n",
    "    .add(\"InvoiceDate\", StringType()) \\\n",
    "    .add(\"UnitPrice\", StringType()) \\\n",
    "    .add(\"CustomerID\", StringType()) \\\n",
    "    .add(\"Country\", StringType())\n",
    "\n",
    "# ==========================\n",
    "# 4. Bronze: Raw Ingestion from Event Hub\n",
    "# ==========================\n",
    "df_raw = (spark.readStream\n",
    "          .format(\"eventhubs\")\n",
    "          .options(**ehConf)\n",
    "          .load())\n",
    "\n",
    "# Parse binary body to structured columns\n",
    "bronze_df = (df_raw\n",
    "             .selectExpr(\"CAST(body AS STRING) as json\")\n",
    "             .select(from_json(col(\"json\"), schema).alias(\"data\"))\n",
    "             .select(\"data.*\"))\n",
    "\n",
    "bronze_path = config[\"delta_tables\"][\"bronze_path\"]\n",
    "display(bronze_df )\n",
    "\n",
    "df_clean = (bronze_df\n",
    "            .withColumn(\"Quantity\", col(\"Quantity\").cast(IntegerType()))\n",
    "            .withColumn(\"UnitPrice\", col(\"UnitPrice\").cast(DoubleType())))\n",
    "display(df_clean)\n",
    "bronze_query = (df_clean.writeStream\n",
    "                .format(\"delta\")\n",
    "                .option(\"checkpointLocation\", bronze_path + \"/_checkpoint\")\n",
    "                .outputMode(\"append\")\n",
    "                .start(bronze_path))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze-rt",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}